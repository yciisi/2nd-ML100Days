{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作業\n",
    "礙於不是所有同學都有 GPU ，這邊的範例使用的是簡化版本的 ResNet，確保所有同學都能夠順利訓練!\n",
    "\n",
    "\n",
    "最後一天的作業請閱讀這篇非常詳盡的[文章](https://blog.gtwang.org/programming/keras-resnet-50-pre-trained-model-build-dogs-cats-image-classification-system/)，基本上已經涵蓋了所有訓練　CNN 常用的技巧，請使用所有學過的訓練技巧，盡可能地提高 Cifar-10 的 test data 準確率，截圖你最佳的結果並上傳來完成最後一次的作業吧!\n",
    "\n",
    "另外這些技巧在 Kaggle 上也會被許多人使用，更有人會開發一些新的技巧，例如使把預訓練在 ImageNet 上的模型當成 feature extractor 後，再拿擷取出的特徵重新訓練新的模型，這些技巧再進階的課程我們會在提到，有興趣的同學也可以[參考](https://www.kaggle.com/insaff/img-feature-extraction-with-pretrained-resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import models, layers, optimizers\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base = ResNet50(weights='imagenet', include_top=False, input_shape=(200, 200, 3))\n",
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelTL():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.UpSampling2D((2,2)))\n",
    "    model.add(layers.UpSampling2D((2,2)))\n",
    "    model.add(layers.UpSampling2D((2,2)))\n",
    "    model.add(conv_base)\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train = x_train / 255.\n",
    "x_test = x_test / 255.\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "epochs = 2\n",
    "\n",
    "model = modelTL()\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=2e-5),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, BatchNormalization, Activation, Input, AveragePooling2D, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    lr = 1e-3\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr\n",
    "\n",
    "# 使用 resnet_layer 來建立我們的 ResNet 模型\n",
    "def resnet_layer(inputs,\n",
    "                 num_filters=16,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 activation='relu',\n",
    "                 batch_normalization=True,\n",
    "                 conv_first=True):\n",
    "    # 建立卷積層\n",
    "    conv = Conv2D(num_filters,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=strides,\n",
    "                  padding='same',\n",
    "                  kernel_initializer='he_normal',\n",
    "                  kernel_regularizer=l2(1e-4))\n",
    "\n",
    "    # 對輸入進行卷機，根據 conv_first 來決定 conv. bn, activation 的順序\n",
    "    x = inputs\n",
    "    if conv_first:\n",
    "        x = conv(x)\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "    else:\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "        x = conv(x)\n",
    "    return x\n",
    "\n",
    "# Resnet v1 共有三個 stage，每經過一次 stage，影像就會變小一半，但 channels 數量增加一倍。ResNet-20 代表共有 20 層 layers，疊越深參數越多\n",
    "def resnet_v1(input_shape, depth=8, num_classes=10):\n",
    "\n",
    "    if (depth - 2) % 6 != 0:\n",
    "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n",
    "    # 模型的初始設置，要用多少 filters，共有幾個 residual block （組成 ResNet 的單元）\n",
    "    num_filters = 16\n",
    "    num_res_blocks = int((depth - 2) / 6)\n",
    "    \n",
    "    # 建立 Input layer\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # 先對影像做第一次卷機\n",
    "    x = resnet_layer(inputs=inputs)\n",
    "    \n",
    "    # 總共建立 3 個 stage\n",
    "    for stack in range(3):\n",
    "        # 每個 stage 建立數個 residual blocks (數量視你的層數而訂，越多層越多 block)\n",
    "        for res_block in range(num_res_blocks):\n",
    "            strides = 1\n",
    "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
    "                strides = 2  # downsample\n",
    "            y = resnet_layer(inputs=x,\n",
    "                             num_filters=num_filters,\n",
    "                             strides=strides)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters,\n",
    "                             activation=None)\n",
    "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
    "                # linear projection residual shortcut connection to match\n",
    "                # changed dims\n",
    "                x = resnet_layer(inputs=x,\n",
    "                                 num_filters=num_filters,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            x = keras.layers.add([x, y]) # 此處把 featuremaps 與 上一層的輸入加起來 (欲更了解結構需閱讀原論文)\n",
    "            x = Activation('relu')(x)\n",
    "        num_filters *= 2\n",
    "\n",
    "    # 建立分類\n",
    "    # 使用 average pooling，且 size 跟 featuremaps 的 size 一樣 （相等於做 GlobalAveragePooling）\n",
    "    x = AveragePooling2D(pool_size=8)(x)\n",
    "    y = Flatten()(x)\n",
    "    \n",
    "    # 接上 Dense layer 來做分類\n",
    "    outputs = Dense(num_classes,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "\n",
    "    # 建立模型\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "y_train shape: (50000, 1)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256  \n",
    "epochs = 50\n",
    "num_classes = 10\n",
    "subtract_pixel_mean = True\n",
    "num_classes = 10\n",
    "n = 1\n",
    "version = 1\n",
    "depth = n * 6 + 2\n",
    "model_type = 'ResNet%dv%d' % (depth, version)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "input_shape = x_train.shape[1:]\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "if subtract_pixel_mean:\n",
    "    x_train_mean = np.mean(x_train, axis=0)\n",
    "    x_train -= x_train_mean \n",
    "    x_test -= x_train_mean\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print('y_train shape:', y_train.shape)\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 32, 32, 16)   448         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2 (BatchNo (None, 32, 32, 16)   64          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 32, 32, 16)   0           batch_normalization_v2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 16)   2320        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_1 (Batch (None, 32, 32, 16)   64          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_v2_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 16)   2320        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_2 (Batch (None, 32, 32, 16)   64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 32, 32, 16)   0           activation[0][0]                 \n",
      "                                                                 batch_normalization_v2_2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 16)   0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 16, 16, 32)   4640        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_3 (Batch (None, 16, 16, 32)   128         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 16, 16, 32)   0           batch_normalization_v2_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 16, 16, 32)   9248        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 16, 16, 32)   544         activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_4 (Batch (None, 16, 16, 32)   128         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 16, 16, 32)   0           conv2d_5[0][0]                   \n",
      "                                                                 batch_normalization_v2_4[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 16, 16, 32)   0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 8, 8, 64)     18496       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_5 (Batch (None, 8, 8, 64)     256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 8, 8, 64)     0           batch_normalization_v2_5[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 8, 8, 64)     36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 8, 8, 64)     2112        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_6 (Batch (None, 8, 8, 64)     256         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 8, 8, 64)     0           conv2d_8[0][0]                   \n",
      "                                                                 batch_normalization_v2_6[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 8, 8, 64)     0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 1, 1, 64)     0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 64)           0           average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           650         flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 78,666\n",
      "Trainable params: 78,186\n",
      "Non-trainable params: 480\n",
      "__________________________________________________________________________________________________\n",
      "ResNet8v1\n"
     ]
    }
   ],
   "source": [
    "model = resnet_v1(input_shape=input_shape, depth=depth)\n",
    "\n",
    "# 編譯模型，使用 Adam 優化器並使用學習率動態調整的函數，０代表在第一個 epochs\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=lr_schedule(0)),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "print(model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Learning rate:  0.001\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 82s 2ms/sample - loss: 1.6814 - accuracy: 0.4153 - val_loss: 2.5471 - val_accuracy: 0.1883\n",
      "Learning rate:  0.001\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 75s 1ms/sample - loss: 1.3320 - accuracy: 0.5458 - val_loss: 1.6303 - val_accuracy: 0.4128\n",
      "Learning rate:  0.001\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 70s 1ms/sample - loss: 1.1690 - accuracy: 0.6057 - val_loss: 1.2855 - val_accuracy: 0.5561\n",
      "Learning rate:  0.001\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 78s 2ms/sample - loss: 1.0723 - accuracy: 0.6402 - val_loss: 1.1513 - val_accuracy: 0.6170\n",
      "Learning rate:  0.001\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 81s 2ms/sample - loss: 1.0045 - accuracy: 0.6642 - val_loss: 1.5308 - val_accuracy: 0.5180\n",
      "Learning rate:  0.001\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 71s 1ms/sample - loss: 0.9440 - accuracy: 0.6891 - val_loss: 1.1140 - val_accuracy: 0.6250\n",
      "Learning rate:  0.001\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 72s 1ms/sample - loss: 0.8985 - accuracy: 0.7031 - val_loss: 1.1078 - val_accuracy: 0.6311\n",
      "Learning rate:  0.001\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 82s 2ms/sample - loss: 0.8615 - accuracy: 0.7183 - val_loss: 1.0197 - val_accuracy: 0.6567\n",
      "Learning rate:  0.001\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 76s 2ms/sample - loss: 0.8244 - accuracy: 0.7335 - val_loss: 1.0931 - val_accuracy: 0.6383\n",
      "Learning rate:  0.001\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 73s 1ms/sample - loss: 0.7934 - accuracy: 0.7426 - val_loss: 1.0249 - val_accuracy: 0.6600\n",
      "Learning rate:  0.001\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 81s 2ms/sample - loss: 0.7623 - accuracy: 0.7544 - val_loss: 1.1071 - val_accuracy: 0.6548\n",
      "Learning rate:  0.001\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 76s 2ms/sample - loss: 0.7300 - accuracy: 0.7660 - val_loss: 1.0077 - val_accuracy: 0.6757\n",
      "Learning rate:  0.001\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 81s 2ms/sample - loss: 0.7104 - accuracy: 0.7724 - val_loss: 1.0478 - val_accuracy: 0.6642\n",
      "Learning rate:  0.001\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 76s 2ms/sample - loss: 0.6816 - accuracy: 0.7818 - val_loss: 1.3100 - val_accuracy: 0.5976\n",
      "Learning rate:  0.001\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 80s 2ms/sample - loss: 0.6638 - accuracy: 0.7910 - val_loss: 1.2438 - val_accuracy: 0.6280\n",
      "Learning rate:  0.001\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 77s 2ms/sample - loss: 0.6381 - accuracy: 0.7999 - val_loss: 1.0573 - val_accuracy: 0.6622\n",
      "Learning rate:  0.001\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 70s 1ms/sample - loss: 0.6178 - accuracy: 0.8064 - val_loss: 1.1490 - val_accuracy: 0.6503\n",
      "Learning rate:  0.001\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 71s 1ms/sample - loss: 0.6061 - accuracy: 0.8104 - val_loss: 0.9918 - val_accuracy: 0.6819\n",
      "Learning rate:  0.001\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 81s 2ms/sample - loss: 0.5802 - accuracy: 0.8203 - val_loss: 1.3428 - val_accuracy: 0.6123\n",
      "Learning rate:  0.001\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 80s 2ms/sample - loss: 0.5601 - accuracy: 0.8277 - val_loss: 1.1547 - val_accuracy: 0.6608\n",
      "Learning rate:  0.001\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 81s 2ms/sample - loss: 0.5475 - accuracy: 0.8329 - val_loss: 1.1451 - val_accuracy: 0.6557\n",
      "Learning rate:  0.001\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 80s 2ms/sample - loss: 0.5275 - accuracy: 0.8406 - val_loss: 1.1417 - val_accuracy: 0.6558\n",
      "Learning rate:  0.001\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 82s 2ms/sample - loss: 0.5165 - accuracy: 0.8431 - val_loss: 1.1358 - val_accuracy: 0.6606\n",
      "Learning rate:  0.001\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 72s 1ms/sample - loss: 0.5000 - accuracy: 0.8479 - val_loss: 1.1629 - val_accuracy: 0.6620\n",
      "Learning rate:  0.001\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 72s 1ms/sample - loss: 0.4878 - accuracy: 0.8537 - val_loss: 1.3025 - val_accuracy: 0.6567\n",
      "Learning rate:  0.001\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 82s 2ms/sample - loss: 0.4654 - accuracy: 0.8626 - val_loss: 1.4261 - val_accuracy: 0.6187\n",
      "Learning rate:  0.001\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 79s 2ms/sample - loss: 0.4606 - accuracy: 0.8628 - val_loss: 1.3383 - val_accuracy: 0.6560\n",
      "Learning rate:  0.001\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 77s 2ms/sample - loss: 0.4424 - accuracy: 0.8699 - val_loss: 1.3860 - val_accuracy: 0.6306\n",
      "Learning rate:  0.001\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 84s 2ms/sample - loss: 0.4285 - accuracy: 0.8767 - val_loss: 1.2818 - val_accuracy: 0.6550\n",
      "Learning rate:  0.001\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 74s 1ms/sample - loss: 0.4200 - accuracy: 0.8786 - val_loss: 1.2407 - val_accuracy: 0.6748\n",
      "Learning rate:  0.001\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 82s 2ms/sample - loss: 0.4084 - accuracy: 0.8818 - val_loss: 1.2475 - val_accuracy: 0.6627\n",
      "Learning rate:  0.001\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 80s 2ms/sample - loss: 0.3932 - accuracy: 0.8877 - val_loss: 1.1247 - val_accuracy: 0.6942\n",
      "Learning rate:  0.001\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 72s 1ms/sample - loss: 0.3850 - accuracy: 0.8922 - val_loss: 1.3261 - val_accuracy: 0.6637\n",
      "Learning rate:  0.001\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 79s 2ms/sample - loss: 0.3833 - accuracy: 0.8905 - val_loss: 1.2281 - val_accuracy: 0.6846\n",
      "Learning rate:  0.001\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 77s 2ms/sample - loss: 0.3668 - accuracy: 0.8976 - val_loss: 1.1908 - val_accuracy: 0.6878\n",
      "Learning rate:  0.001\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 72s 1ms/sample - loss: 0.3603 - accuracy: 0.9010 - val_loss: 1.1764 - val_accuracy: 0.6768\n",
      "Learning rate:  0.001\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 81s 2ms/sample - loss: 0.3508 - accuracy: 0.9030 - val_loss: 1.4440 - val_accuracy: 0.6403\n",
      "Learning rate:  0.001\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 80s 2ms/sample - loss: 0.3415 - accuracy: 0.9075 - val_loss: 1.7109 - val_accuracy: 0.6234\n",
      "Learning rate:  0.001\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 72s 1ms/sample - loss: 0.3328 - accuracy: 0.9110 - val_loss: 1.2520 - val_accuracy: 0.6820\n",
      "Learning rate:  0.001\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 72s 1ms/sample - loss: 0.3243 - accuracy: 0.9139 - val_loss: 1.3222 - val_accuracy: 0.6769\n",
      "Learning rate:  0.001\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 72s 1ms/sample - loss: 0.3164 - accuracy: 0.9170 - val_loss: 1.6884 - val_accuracy: 0.6308\n",
      "Learning rate:  0.001\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 72s 1ms/sample - loss: 0.3126 - accuracy: 0.9185 - val_loss: 1.4614 - val_accuracy: 0.6723\n",
      "Learning rate:  0.001\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 72s 1ms/sample - loss: 0.3093 - accuracy: 0.9185 - val_loss: 2.0172 - val_accuracy: 0.5962\n",
      "Learning rate:  0.001\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 72s 1ms/sample - loss: 0.2983 - accuracy: 0.9236 - val_loss: 1.8824 - val_accuracy: 0.6205\n",
      "Learning rate:  0.001\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 72s 1ms/sample - loss: 0.2933 - accuracy: 0.9250 - val_loss: 1.3109 - val_accuracy: 0.6823\n",
      "Learning rate:  0.001\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 72s 1ms/sample - loss: 0.2880 - accuracy: 0.9273 - val_loss: 1.4791 - val_accuracy: 0.6703\n",
      "Learning rate:  0.001\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 73s 1ms/sample - loss: 0.2839 - accuracy: 0.9276 - val_loss: 1.5295 - val_accuracy: 0.6504\n",
      "Learning rate:  0.001\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 72s 1ms/sample - loss: 0.2702 - accuracy: 0.9353 - val_loss: 1.5378 - val_accuracy: 0.6528\n",
      "Learning rate:  0.001\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 73s 1ms/sample - loss: 0.2685 - accuracy: 0.9345 - val_loss: 1.7540 - val_accuracy: 0.6376\n",
      "Learning rate:  0.001\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 72s 1ms/sample - loss: 0.2647 - accuracy: 0.9356 - val_loss: 1.6272 - val_accuracy: 0.6451\n",
      "10000/10000 [==============================] - 3s 269us/sample - loss: 1.6272 - accuracy: 0.6451\n",
      "Test loss: 1.6272336875915527\n",
      "Test accuracy: 0.6451\n"
     ]
    }
   ],
   "source": [
    "# 使用動態調整學習率\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "# 使用自動降低學習率 (當 validation loss 連續 5 次沒有下降時，自動降低學習率)\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "                               cooldown=0,\n",
    "                               patience=5,\n",
    "                               min_lr=0.5e-6)\n",
    "# 設定 callbacks\n",
    "callbacks = [lr_reducer, lr_scheduler]\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    zca_epsilon=1e-06,\n",
    "    rotation_range=0,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.,\n",
    "    zoom_range=0.,\n",
    "    channel_shift_range=0.,\n",
    "    fill_mode='nearest',\n",
    "    cval=0.,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    rescale=None,\n",
    "    preprocessing_function=None,\n",
    "    data_format=None,\n",
    "    validation_split=0.0)\n",
    "\n",
    "# 將資料送進 ImageDataGenrator 中做增強\n",
    "datagen.fit(x_train)\n",
    "\n",
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                    steps_per_epoch=int(len(x_train)//batch_size),\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    epochs=epochs, verbose=1, workers=4,\n",
    "                    callbacks=callbacks)\n",
    "\n",
    "# 評估我們的模型\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
